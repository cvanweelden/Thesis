
\section*{Short description of graduation project.}

%what is metric learning, what is the problem
Metric learning is the problem of learning a distance function between data samples which satisfies some given constraints. Metric learning methods are useful in machine learning problems where the decision rule is based on the distance between samples represented by points in a numerical feature space. For example, in $k$-nearest neighbor classification each sample is classified as belonging to the majority class amongst its neighbors in feature space, thus we would constrain distances between points of the same class to be small and distances between points of different classes to be large in order for the nearest-neighbor decision rule to be effective. Other machine learning methods that depend on distances in feature space, such as support vector machines, $k$-means clustering, and kernel density estimation, would benefit from similar constraints on the distance function in feature space.

Most metric learning methods depend on samples being assigned to disjunct classes in order to generate constraints for learning the distance function. These methods are applicable to learning problems characterized by $0/1$-loss. However, in some learning problems the quantity of interest is a distance measure which represents some form of similarity or difference between data points, e.g. age difference between people or semantic overlap between images. Similarly, in structured prediction problems the loss function is real-valued, since the number of possible predictions is very large or even infinite and some of these predictions are closer to the truth than others, making $0/1$-loss uninformative. Metric learning methods that depend on class-equivalence constraints are not applicable to these problems.

%what do we do, what questions do we answer, how do we answer these questions, 
This thesis investigates how we can apply metric learning methods to learning problems which have a real-valued loss function, such as regression problems and structured prediction problems. We propose a method which views metric learning as a regression problem in the space of semi-definite matrices to learn a Mahalanobis distance which satisfies real-valued constraints. Satisfying these constraints aligns the feature space to the ground-truth space in which the loss function is measured, hence we refer to our method as \emph{metric alignment}. We apply this method to images taken from a semantic segmentation problem in which we learn to predict semantic overlap between image patches without knowing the correct segmentations, and to images from an attribute-based classification problem where we learn to predict an attribute vector from the image features. We compare our method against existing methods where we threshold the real-valued loss in order to generate constraints based on $0/1$-loss. 

To summarize: the main contributions of this thesis are:
\begin{itemize}
\item We describe a method for applying metric learning to problems characterized by a real-valued loss function.
\item We introduce two learning problems based on existing datasets that can be used to evaluate metric learning methods for real-valued loss.
\item We evaluate our method against existing methods on these learning problems.
\end{itemize}

\end{document}