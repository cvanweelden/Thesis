


%3.5(bad) student network example
%3.7 proposed method should be used when you need a distance function measuring similarity or a feature space in which Euclidean distances correspond to similarity between objects for which it is difficult to decide whether they belong to the same discrete class and the similarity you want to measure is known for at least a subset of the training set but not for new examples but training and test objects can be represented by the same set of features.

%4.1 metric alignment, continuous distance functions, unknown or unavailable during execution, transforms feature space, feature distances are predictive of training distance
%3.4-2 metric alignment, learn a metric that satisfies real similarity score



%dimension reduction and visualization methods, (multi-dimensional scaling, isomap, LLE, SNE), mapping/embedding retaining pairwise distances, finding coordinates in some space which satisfy a similarity score



\section{Introduction.}

%2.1 objects represented as vectors of feature values, feature space
%1.1-1 machine learning features, feature space,
In machine learning tasks, objects of interest are represented using a set of features. Features correspond to attributes of the object that can be encoded in some way. For example the features representing images may simply be the pixel values of an image, but may also be more complex features computed from the basic pixel values. Each object is thus represented by a feature vector containing the feature values. We will refer to the space of all possible feature vectors as the feature space and in the case of $n$-dimensional real-valued vectors take this space to be $\mathbb{R}^n$.

%2.2-1 measure similarity by assuming small difference in feature vector means similar objects,
%1.1-2 measuring distance, finding similar samples, Euclidean distance
%computing distance between data samples fundamental problem
%3.1-1 similarity between objects, distance function,
Now suppose we would like to measure similarities between objects. For example, we have some images of a Ferrari car and we want to find images of similar cars. Assuming that similar objects result in similar feature values, we can express similarity between objects as a distance function in feature space. For our $\mathbb{R}^n$ feature space we can therefore measure similarity by Euclidean distance between the points in the feature space given by the feature vectors. Thus, starting from the feature representations of our input images we would expect to find images of similar cars nearer in feature space than images of dissimilar cars.

%3.2 representation of objects, feature space, distance in this space different from similarity, explain problem with clustering: picking different features or scaling will lead to different clusters which do not all correspond to our idea of similarity, common to use Euclidean or Hamming distance depending on the feature vector
%2.3-1 feature difference not always good measure for similarity,
However, Euclidean distance is not necessarily the best measure for similarity. In most cases features are predetermined since they measure basic attributes of the object, but the kind of similarity we want to measure is specific to the task. With Euclidean distance each feature has an equal impact on the distance, even though some features are much more relevant to the type of similarity we want to measure than others. For example in our car images example, we would want to focus on similarities in color if we are simply looking for other red cars, but we would want to look at more complex similarities in shape if we are looking for other racing cars. 

%1.2 use of metric in machine learning methods, kNN, k-means, SVM, effectiveness depends on metric
%2.2-2 used by kNN and k-means
%3.1-2 applications (clustering, non-parametric methods based on distance or local density [kernel density estimation, k-nearest neighbor classification], visual identification)
Several machine learning methods use a distance function at the core of their algorithm. For example, the \ac{kNN} algorithm classifies objects by searching the training data for feature vectors that are closest to the input vector. The objects corresponding to these nearest neighbors then vote on the class to assign to the input object. It is clear that for this to be effective, distances in feature space should be small for objects of the same class and large for objects of differing class. Similarly, the $k$-means clustering algorithm clusters samples based on their distances in feature space. This will cluster similar objects together if they are close together in feature space. These methods require us to carefully choose a feature representation and distance function in order to be effective.

%1.3-1 metric learning, parametric distance function, learn parameters,
%2.3-2 metric learning: learn distance function that is more useful
%3.3-1 metric learning: learn a distance function between object representations that corresponds to actual similarity, metric, parametric metrics, metric transform, Mahalanobis distance,
Instead of hand-crafting a distance function, we can automatically learn a suitable distance function in a given feature space. This approach is called \emph{metric learning}. Metric learning methods define a parametric distance function and then learn the best parameters for this function. Learning the parameters requires a set of training samples in the given feature space \todo{Rewrite rest of this sentence as a new sentence.} and constraints on the distances between training samples that represent the similarity measure that we want the distance function to conform to. For example, if we are still looking for images of similar racing cars, we would provide samples of racing cars and then constrain the distances between these to be small.

%1.3-2 constraints based on class of samples
%2.4-1 train metric on class differences,
%3.3-2 using discrete similarity for training or a similarity ranking,
Metric learning has mostly been used in the context of multi-class classification problems and ranking problems. Hence, the constraints generally take the form of equivalence constraints or ranking constraints. Equivalence constraints are generated from class labels: objects of the same class are constrained to have a small pairwise distance while objects of different classes are constrained to have a larger distance. Ranking constraints consists of triplets of points for which we constrain one pairwise distance to be smaller than another pairwise distance.

%3.4-1 what if we have exact similarity scores represented as real numbers, but not discrete classes, e.g. structured problem
%research questions: how can metric learning be applied to real-valued loss, how does this compare to existing problems
However, there is a more direct approach to the metric learning problem that has not received much attention in the literature. Instead of generating equivalence or ranking constraints, a metric can be trained on real-valued constraints that directly specify what the distance between a given pair of points in feature space should be. This thesis investigates the use of real-valued constraints in metric learning and attempts to answer the following research questions:
\begin{itemize}
\item How can we apply metric learning methods to problems with real-valued constraints.
\item How does metric learning with real-valued constraints compare to methods relying on equivalence or ranking constraints.
\end{itemize}

%how do we answer these questions
%4.2 classification problems with continuous loss function, nearest neighbor methods
We will answer these questions by investigating a class of machine learning problems that permits us to generate real-valued distance constraints, namely \emph{structured prediction} problems. Structured prediction problems are classification problems in which the goal is not to predict a single label, but to predict a complex output structure. For example, predicting a label sequence. Unlike class labels, which are always either correct or incorrect, structured outputs can be partly correct. Therefore, such problems define a continuous loss function which measures the divergence between two output structures. Our approach will be to use this loss function to generate real-valued constraints on which to train our metric learning method.

\begin{figure}[t]
\begin{center}
\missingfigure{\tiny{Two 2D plots side-by-side. Left plot showing 4 points connected to a central point. Connecting lines are labeled by Euclidean distance, points are labeled by ground-truth distance. Top and bottom point should have large distance (e.g. 3,4) while middle points should have small distance (e.g. 1), but now all have about 2 distance. Right plot shows points in transformed space, the center points are now closer to 1 distance while the other two points are now closer to 3, 4 distance. Also show metrics as ellipses (covariance matrices) making clear that our method learns these parameters.}}
\caption{}
\label{fig:approach_overview}
\end{center}
\end{figure}

%our approach differs from existing metric learning methods
%target metric
%1.4 real-valued loss function instead of nominal values for classes, metric proportional to loss, predict loss from feature space by learning metric on real-valued constraints
%2.4-2 we train on real-valued ground-truth metric, such as real-valued loss function in structured prediction problems
Figure \ref{fig:approach_overview} shows a graphical example of our approach.
Thus we align our distance function in feature space to the loss function in our structured output space. Hence we refer to our approach as \emph{metric alignment}.
There are other learning problems in which samples are not taken from disjunct classes, but in which there is a real-valued loss function. In this case, we would like our metric learning method to learn a distance function which is proportional to this loss. However, this loss is not measured in feature space, but in a ground-truth space. But for testing samples we do not have this ground truth, so we need to learn a distance function in the feature space which is aligned with the loss function in ground-truth space. Like in the $0/1$-loss case we can generate distance constraints from this real loss in order to train a parametric distance function. This thesis describes how this can be done and evaluates it on two datasets with real-valued loss functions.
 In contrast to these methods, we investigate whether we can make use of a real-valued ground-truth metric in order to learn a distance metric in feature space. This is useful in cases where the problem has a real-valued loss function which can be computed between data in the training set, but not at testing time when we have no access to the ground truth. Such a real-valued loss function is generally found in structured prediction tasks, where loss has to be measured between complex answers for which $0/1$-loss is uninformative.


%4.3 kNN for structured prediction, performs best when distance function is small if loss is small for k=1, have to predict loss from feature space
Now suppose we would like to apply \acf{kNN} classification to such a structured problem. In \ac{kNN} classification we predict an output by looking at the output corresponding to the $k$ closest training examples. Suppose we set $k = 1$ and we simply predict the output we have observed for the closest training example. This approach performs best when the closest example is the example with the lowest loss relative to the ground truth label. However, we do not have this loss available during execution to rank neighbors, thus `closest' is defined here as smallest distance in feature space. Hence, if we train our metric to be predictive of the pairwise loss, we might increase our performance.


%contributions: describes method for metric learning with real-valued constraints, describes evaluation problem and datasets, evaluates described and related methods on real-valued constraints
To summarize: the main contributions of this thesis are:
\begin{itemize}
\item We describe a method for applying metric learning to problems characterized by a real-valued loss function.
\item We introduce two learning problems based on existing datasets that can be used to evaluate metric learning methods for real-valued loss.
\item We evaluate our method against existing methods on these learning problems.
\end{itemize}
